Оглавление

	Что это

	Где и когда использовать

	Что умеет

	Установка

	Советы по работе

	Нюансы

	Пример

	Запуск в фоне

	Команды

Что это

	Celery - это инструмент, который позволяет выполнять задачи в фоновом режиме. Или распределённая очередь задач.

Где и когда использовать

	Использовать всё в одном процессе веб-сервера это плохая идея, потому что время отклика приложения будет долгим. Например после успешного заказа пользователем билета на самолёт мы должны отправить ему сообщение на почту, забронировать место другую стороннюю систему и провести платёж в 1С. Именно в такой ситуации напомощь нам приходит Celery. 

	Если нет обмена задачами между приложениями, то можно использовать только Celery.

	Если задача простая, то лучше использовать что-нибудь полегче, чем Celery.

	Более простая альтернатива Celery это RQ.

	Celery может выступать в качестве поставщика сообщений в брокер.

Что умеет

	Выполнять задания асинхронно или синхронно

	Выполнять периодические задания

	Выполнять отложенные задания

	Распределенное выполнение (может быть запущен на N серверах)

	В пределах одного worker'а возможно конкурентное выполнение нескольких задач (одновременно)

	Выполнять задание повторно, если вылез exception

	Ограничивать количество заданий в единицу времени (rate limit, для задания или глобально)

	Routing заданий

	Выполнять подзадания

	Присылать отчеты об exception на email

	Проверять выполнилось ли задание

Установка

	pip install celery

Советы по работе

	Не использовать базу данных в качестве брокера

		Брокер отвечает за передачу задач исполнителям.
		
		База данных не предназанченна для того, чтобы быть брокером.

		С ростом количества исполнителей, нагрузка на базу будет только возрастать.

	Разделять задачи по очередям

		Если все задачи складировать в одну очередь, то в один прекрасный момент она может забиться, поставив под угрозу выполнение критически важного кода.

		Как вариант можно разделять очереди по приоритетам: high, normal, low.

	Не запускать исполнителей без привязке к очереди

		При использовании раздельных очередей задач, не запускайте исполнителей без указания для них явного наименования очереди, потому что если например все исполнители, которые слушают очередь high будут заняты, то celery автоматом отправит новую задачу исполнителям без конкретной очереди.

	Логгировать ошибки

		По-умолчанию Celery все ошибки пишет в stderr.

		Контролировать вывод ошибок можно через стандартный python logging, достаточно повесить свой handler на logger под названием celery.

	Писать маленькие задачи и разносить части логики по отдельным методам

		Например, если вам необходимо генерировать и отправлять отчёт, то не нужно в самом task писать код генерации и отправки. Разбейте его на 2 части: 

			метод генерации отчёта

			метод отправки письма

		А внутри метода задачи вызываем 2 метода, которые делают всю работу.

	Гасите вовремя задачи

		Явно указывайте временной лимит на выполнение задачи.

		Это нужно делать, потому что в некоторых случаях его отсутствие попросту приведёт к зависанию исполнителя.

	Не хранить результаты исполнения без необходимости

		Если результаты всё-таки нужно хранить, то лучше это делать в redis.

	Не использовать ORM объекты в качестве аргументов

		Лучшим решением будет передача идентификатора объекта в базе данных, а в самой task функции необходимо непосредственно обращаться к объекту через его id.

	Задавать visibility_timeout равным самому длительному eta/countdown в вашем проекте

		При использовании отложенных задач может случиться так, что одну задачу будут выполнять все воркеры.

		Так может происходить по причине того, что время, через которое должна выполниться задача, превышает visibility_timeout. 

		По умолчанию для Redis этот параметр равен 1 часу. 

		То есть если вы укажете выполнение задачи через 2 часа, то демон celery подождёт 1 час, поймёт, что никто из доступных воркеров не откликнулся и насильно назначит всем воркерам её выполнение.

	Старайтесь не использовать Celery для выполнения долгих задач

		Celery заточен на выполнение большого количества задач, требующих мало времени на их исполнение. Когда задачи тяжелые и выполняются долго, образуются очереди.

		Процессы, живущие долго, потребляют память, но не освобождают её. Поэтому в контексте использования Celery с ними иногда имеет смысл перезагружать воркеры после выполнения заданного количества тасков. За это отвечает параметр CELERYD_MAX_TASKS_PER_CHILD

Нюансы

	Результаты выполнения задачи по умолчанию выключенны. Для включения использовать:

		backend='rpc://' в app = Celery()

	Если celery используется только в связке с брокером, то нельзя получить результат выполнения задачи.

	Для того чтобы получить результат выполнения задачи можно использовать celery в связке celery + брокер + backend или result.get(timeout=1)

	В качестве backend может выступать например redis. Тогда результат можно получить так:  	

		result = add.delay(4, 4)
		result.ready()

Пример

	from celery import Celery

	app = Celery('first_step', backend='rpc://', broker='amqp://localhost') - коннектимся к брокеру

	@app.task - создаём задачу
	def add(x, y):
	    return x + y

	result = add.delay(4, 4) - выполняем задачу

	result.get(timeout=1) - для получения результата выполнения задачи (если не используем бэкенд)

	add.apply_async((2, 2), queue='lopri', countdown=10) - выполняем задачу и даёт расширенный контроль над этим процессом

Запуск в фоне

	Можно запустить воркеры celery в фоновом режиме.

	celery multi start w1 -A tasks -l info - запускает воркер в фоне

	celery multi restart w1 -A tasks -l info - перезапускает воркер в фоне

	celery multi stop w1 -A proj -l info - останавливает фоновый воркер

	Логирование работы воркеров по умолчанию будет сохраняться в текущую директорию.

Canvas

	Нужен для того чтобы передать для выполнения задачу в другую задачу.

	add.s(2, 2) - возвращает задачу, которую потом можно выполнить

	s1 = add.s(4, 4)
	res = s1.delay()

	Пример:

		def create(task):
			task.delay()

		def delete(task):
			task.delay()

		task = add.s(2, 2)

		create(task)
		delete(task)

Groups

	Позволяют выполнять список задач.

	g = group(add.s(i) for i in range(10))

Chains

	Связывает вызов задач.

	Когда первая выполнилась, запускаетс вторая.

	chain(add.s(4) | mul.s(8))

Chords

	Позволяет выполнять список задач с callback

Routing

	Позволяет отправлять задачу в конкретную очередь.

	celery -A tasks worker -Q queue_name - создаёт воркер с очередью

	add.apply_async((2, 2), queue='hipri')

Команды

	celery -A tasks worker --loglevel=info - запуск (делать в директории с файлом tasks.py, tasks - имя файла)

	celery multi start w1 -A tasks -l info - запускает воркер в фоне

	celery multi restart w1 -A tasks -l info - перезапускает воркер в фоне

	celery multi stop w1 -A proj -l info - останавливает фоновый воркер

	celery -A tasks worker -Q queue_name - создаёт воркер с очередью

	Смотреть в конце next steps:

	celery -A proj inspect active - 

	celery -A proj control enable_events - 

	celery -A proj events --dump - 

	celery -A proj events - 

	celery -A proj control disable_events - 

	celery -A proj status -







