Оглавление

	Что это

	Отличия от Apache

	Как это работает

	Архитектура

	Главный конфигурационный файл

	Глобальная секция

	Секция http

	Секция server

	Как nginx обрабатывает запросы

	Nginx как обратный прокси-сервер

	Модуль upstream

	Кэширование соединений

	Алгоритмы балансировки нагрузки

	Типы проксируемых серверов

	Проксируемые серверы uWSGI

	Условие if в настройке проксируемого сервера

	Отлов ошибок проксирования

	Техника устранения неполадок

	Оптимальная настройка

	Docker

	Нюансы

	Команды

	Проблема 10000 соединений

Что это

	Это web сервер.

	Web сервер — это компьютерная программа, запускаемая на подключённом к сети компьютере и использующая протокол HTTP для передачи данных. 

	В простейшем виде такая программа получает по сети HTTP-запрос на определённый ресурс, находит соответствующий файл на локальном жёстком диске и отправляет его по сети запросившему компьютеру. Более сложные веб-серверы способны в ответ на HTTP-запрос динамически генерировать документы с помощью шаблонов и сценариев.

	Для загрузки и просмотра веб-страниц используются специальные программы — браузеры. Браузер это клиент.

Отличия от Apache

	Apache работает медленнее чем Nginx, потому что тратит больше ресурсов на соединение с клиентом.

	Nginx спроектирована для поддержки свыше 100000 одновременных соединений, но их кол-во также зависит и от железа.

Как это работает

	Клиент делает запрос к серверу. (клиентом может быть как браузер, так и например wget)

	Начинается поиск dns.

	В настройках каждой системы указано местоположение dns. 

	В linux это файл hosts в директории etc. (когда изменили файл, сеть не перезапускать)

	Если dns найден в файле hosts, то запрос идёт дальше к серверу.

	Если сервер получил запрос, то это будет видно в логах.

	Логи находятся /var/log/nginx

	Если запрос добрался до nginx, то это запишется в файл access.log

	Дальше управление берёт на себя web сервер.

	Если web сервер настроен на использование статического контента, то в ответ на запрос отпрвляется файл.

	Если web сервер настроен на использование динамического контента, то запрос отпрвляется в application сервер.

Архитектура

	NGINX состоит из одного главного и нескольких рабочих процессов.

	Все они однопоточные и способны одновременно обслуживать тысячи соединений.

	Большая часть работы производится рабочим процессом.

	Главный процесс NGINX отвечает за чтение конфигурационного файла, работу с сокетами, запуск рабочих процессов, открытие фай- лов журналов и компиляции встроенных скриптов на языке Perl.

	Рабочий процесс NGINX исполняет цикл событий, в котором обрабатываются входящие соединения.

Главный конфигурационный файл

	По умолчанию, конфигурационный файл называется nginx.conf и расположен в каталоге /usr/local/nginx/conf, /etc/nginx/conf.d/default.conf или /usr/local/etc/nginx

	Конфигурационный файл NGINX состоит из секций.

Глобальная секция

	В глобальной секции задаются параметры, оказывающие влияние на сервер в целом. 

	Глобальная секция не заключается в фигурные скобки. 

	Обычно пишется в файле nginx.conf

		user  nginx; - пользователь и группа, от имени которых исполняются рабочие процессы (нужно содать пользователя с этим именем в системе)
		worker_processes  1; - кол-во рабочих процессов

		error_log  /var/log/nginx/error.log warn; - файл куда логгируются ошибки
		pid        /var/run/nginx.pid; - файл в котором храниться id главного процесса

	Глобальная секция должна находиться в начале конфигурационного файла nginx.conf

	В главный файл конфигурации можно подключать файлы. Если указан не полный путь, то NGINX считает, что путь задан относительно главного местоположения конфигурационного файла.

		include /etc/nginx/conf.d/*.conf;

Секция http

	Секция http описывает http сервер. Сюда входят настройки соединения с клиентом, работа со статикой, сокетами, виртуальными серверами и т.д.

Секция server

	Секция server описывает виртуальный сервер. По умолчанию секция server находиться в отдельном файле, который подключается в секцию http. Этот файл называется default.conf. Его можно найти в etc/nginx/conf.d/default.conf.

		server {
			listen 80; - порт (если оставить 80, то в браузере будет работать без указания порта)
    		server_name localhost; - ip адрес

		    location / {
		        root   /usr/share/nginx/html; - директория с файлом
		        index  index.html index.htm; - тип и имя файла
		    }
		}

	В секции server описываются виртуальные сервера.

	Виртуальные сервера отвечают на запросы по протоколу HTTP.

	Описание виртуальных серверов обычно выносят в /etc/nginx/sites-available и /etc/nginx/sites-enabled

	В sites-available лежат конфиги всех виртуальных серверов.

	В sites-enabled лежат конфиги активных виртуальных серверов.	 

	Файл с описанием виртуального сервера подключается внутри секции http.

	Файл с описанием виртуального сервера выглядит так:

		server {
			listen 80; (может быть и так listen 127.32.4.1:8085;)
			server_name www.example.com;

			location / {
				try_files $uri $uri/ @mongrel;
			}

			location @mongrel {
				proxy_pass http://127.0.0.1:8080;
			}
		}

	Директива listen задает комбинацию IP-адреса и номера порта либо путь к сокету в домене UNIX.

	В директиве server_name возможно использование метасимвола *

	Метасимвол * можно указывать вместо поддомена: *.example.com

	Метасимвол * можно указывать вместо домена верхнего уровня www.example.*

	Метасимволы в пути позволяют включить сразу несколько файлов.

	В директиве server_name может быть и регулярное выражение.

	Чтобы определить, какой виртуальный сервер должен обслужить данный запрос, NGINX применяется следующий алгоритм:

		Сопоставить IP-адрес и порт с указанными в директиве listen

		Сопоставить заголовок Host со значением директивы server_name, рассматриваемым как строка

Имена сервера (dns)

	Имена сервера задаются с помощью директивы server_name и определяют, в каком блоке server.

	Имена могут быть заданы точно, с помощью маски или регулярного выражения.

	Поиск в хэш-таблице имён с масками медленнее, чем поиск в хэш-таблице точных имён, поскольку имена сравниваются по доменным частям. 

	Заметьте, что специальное имя с маской вида “.example.org” хранится в хэш-таблице имён с масками, а не в хэш-таблице точных имён.

	Регулярные выражения проверяются последовательно, а значит являются самым медленным и плохо масштабируемым методом.

	По вышеизложенным причинам предпочтительнее использовать точные имена, где это только возможно.

	Например, если к серверу наиболее часто обращаются по именам example.org и www.example.org, то эффективнее будет указать их явно.

Как nginx обрабатывает запросы

	Сначала nginx решает, какой из серверов должен обработать запрос.

	Если каждый сервер слушает один и тот же порт, то nginx проверяет только поле Host.

	Если его значение не соответствует ни одному из имён серверов или в заголовке запроса нет этого поля вовсе, nginx направит запрос в сервер по умолчанию для этого порта.

	Сервер по умолчанию можно задать явно с помощью параметра default_server (listen 80 default_server;)

	Следует иметь в виду, что сервер по умолчанию является свойством слушающего порта, а не имени сервера.

	Запросы без поля Host в заголовке не должны обрабатываться. Для этого нужно определить сервер, который будет их отклонять:

		server {
		    listen      80;
		    server_name "";
		    return      444; - немедленно закрывает соединение
		}

Nginx как обратный прокси-сервер

	Обратный прокси-сервер - это сервер, который принимает запрос клиента и открывает новое соединение с проксируемым сервером от имени клиента.

	Проксируемый (прямой) сервер - это сервер с которым nginx устанавливает соединение для выполнения запроса клиента.

	Обратный прокси (reverse-proxy) позволяет проксировать веб-трафик в обратном направлении: из сети интернет в локальную сеть, в отличие от наиболее часто используемого варианта - из локальной сети в интернет.

	Под обратным проксированием обычно понимается процесс, в котором сервер, получающий запрос от клиента не обрабатывает его полностью самостоятельно, а частично или целиком отправляет этот запрос для обработки другим (upstream) серверам. То есть, не перенаправляет клиента, а самостоятельно отправляет запрос и возвращает полученный ответ обратно клиенту.

	С той зрения проксирования, наиболее важна директива ргоху_pass.
	
	Она принимает один параметр - URI-адрес, на который следует передать запрос.

	Пример:

		location /uri {
			proxy_pass http://localhost:8080/newuri; - запрос пересылается на этот адрес и путь uri заменяется на newuri
		}

		Если первый урл будет определён с помощью регулярного выражения, то первый урл подставится в proxy_pass.

		Если внутри location есть переписывание (rewrite /(.*)$ /index.php?page=$1 break;), то преобразование не производится:

			location / {
				rewrite /(.*)$ /index.php?page=$1 break;
				proxy_pass http://localhost:8080/index; - будет выполнен запрос на index.php?page=<match>
			}

Модуль upstream

	С модулем proxy тесно связан модуль upstream.

	Модуль upstream позволяет описывать группы серверов, которые могут использоваться в директивах proxy_pass, fastcgi_pass, uwsgi_pass, scgi_pass, memcached_pass и grpc_pass.

	Upstream позволяет передавать запросы нескольким проксируемым серверам.

	Директива upstream должна находиться внутри директивы http.

	Пример:

		upstream backend {
		    server one.com;
		    server two.com;
		}

		server {
		    location / {
		        proxy_pass http://backend;
		    }
		}

Кэширование соединений

	Клиент делает запрос, nginx обрабатывает его, открывает новое соединение и перенаправляет запрос на проксируемый сервер.

	Каждое новое соединение открывается в новом рабочем процессе.

	Кэширование соединений полезно, когда nginx должен держать некоторое кол-во соединений постоянно.

	Директива keepalive позволяет установить кол-во постоянных соединений.

	upstream apache {
		server 127.0.0.1:8080;
		keepalive 32; - устанавливает 32 постоянных соединения
	}

	Если для обслуживания запросов потребуется больше 32 соединений, то NGINX их, конечно, откроет. Но по достижении порогового значения NGINX будет закрывать редко используемые соединения, чтобы общее число открытых соединений оставалось равным 32, как указано в директиве keepalive.

Алгоритмы балансировки нагрузки

	Для выбора проксируемого сервера, которому передается очередной запрос, модуль upstream может применять один из трех алгоритмов балансировки нагрузки:

		циклический (по умолчнию выбирается сервер, следующий за тем, который был выбран для обслуживания предыдущего запроса)

		по хеш-коду IP-адреса (ip_hash, запросы от клиентов с заданными IP-адресами должны попадать одному и тому же проксируемому серверу)
		
		с наименьшим количеством соединений (least_conn, передаёт запрос тому серверу у которого количество активных соединений наименьшее)

Типы проксируемых серверов

	Может находиться на другой машине.

	Может быть демоном, который слушает сокет в домене UNIX на локальной машине.

	Может быть сервером Apache.

	Может быть application сервером, например gunicorn.

Проксируемые серверы uWSGI

	NGINX поддерживает подключение к проксируемому серверу с приложениями па Python с помощью модуля uwsgi. 

	Конфигурируется он так же, как модуль fastcgi, только для указания проксируемого сервера служит директива uwsgi_pass.

Условие if в настройке проксируемого сервера

	if можно использовать в сочетании с директивами return и rewrite с флагом last или break, но в остальных случаях лучше избегать. 

	Объясняется это возможностью получить неожиданные результаты.

Отлов ошибок проксирования

	Бывает, что проксируемый сервер не может обработать запрос.

	В таких случаях NGINX можно настроить так, чтобы возвращался документ, хранящийся на локальном диске.

	Таким образом мы можем увидеть в логах NGINX, что он не достучался до application сервера, потом пойти в логи application сервера и узнать конкретную причину.

Техника устранения неполадок

	Прежде чем приступать к длительному сеансу отладки, пытаясь понять, в чем причина проблемы, полезно заглянуть в журналы.

	Все ошибки пишутся в error_log.

	Если же требуется больше информации, то придется включить отладочное протоколирование.

	Для активации отладочного протоколирования на этапе конфигурирования следует задать флаг --with-debug--with-debug. Делать подобное протоколирование в боевой среде не рекомендуется.

	И состав NGINX входит модуль самодиагностики, который выводит статистические данные о работе программы. Этот модуль называется Stub Status и активируется заданием параметра --with-http_stub_status_module на этапе конфигурирования.

	Чтобы увидеть статистику, порождаемую этим модулем, необходимо включить директиву stub_status, задав в ней значение on. 

	Для этого модуля следует создать отдельную секцию location, чтобы ожно было применить список ACL:

	location /nginx_status {
		stub_status on;
		access_log off;
		allow 127.0.0.1;
		deny all;
	}

	Обращение к урлу http://localhost/nginx_status возвращает ответ такого вида:

		Active connections: 2532 - кол-во открытых соединений

		server accepts handled requests

		1476737983 1476737983 3553635810

		Reading: 93 Writing: 13 Waiting: 2426 - 13 означает, что сервер либо обрабатывает запрос, либо читает тело сообщения, либо отправляет ответ клиенту. 93 - сервер читает заголовки запроса, 2426 - соединения имеют тип keepalive и находятся в состоянии ожидания.

Оптимальная настройка

	https://ruhighload.com/Оптимальная+настройка+nginx

Docker

	docker run -p 80:80 --name nginx -v ~/nginx:/usr/share/nginx/html -d nginx

	docker exec -it container_name bash

	cd /etc/nginx/conf.d/default.conf

	apt-get update

	apt-get install nano

	nano /etc/nginx/nginx.conf

		include /etc/nginx/sites-enabled/*.conf;

	nano /etc/nginx/sites-enabled/kaduk.conf

		server {
			listen 80;
    		server_name kaduk;

		    location / {
		        root   /usr/share/nginx/html;
		        index  index.html index.htm;
		    }
		}

	nano /etc/nginx/conf.d/default.conf	

	http://localhost:8080

	docker logs container_name - показывает логи nginx

Нюансы

	Если создаю nginx в docker, то обязательно нужно пробросить порт.

Команды

	nginx -s reload - перезагрузка конфигурации

	service nginx status

	nginx -t -c path_to_nginx.conf - проверяет правильность конфигурационного файла